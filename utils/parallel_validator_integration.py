"""
å¹¶è¡ŒéªŒè¯å™¨é›†æˆç¤ºä¾‹
å±•ç¤ºå¦‚ä½•åœ¨ hajimi_king.py ä¸­é›†æˆå¹¶è¡ŒéªŒè¯ç³»ç»Ÿ
"""

import time
from typing import List, Dict, Tuple
from datetime import datetime

from common.Logger import logger
from utils.parallel_validator import ParallelKeyValidator, ValidationResult, get_parallel_validator


def integrate_parallel_validation(keys: List[str]) -> Tuple[List[str], List[str], Dict[str, ValidationResult]]:
    """
    é›†æˆå¹¶è¡ŒéªŒè¯åˆ°ç°æœ‰æµç¨‹
    
    Args:
        keys: å¾…éªŒè¯çš„å¯†é’¥åˆ—è¡¨
        
    Returns:
        Tuple[valid_keys, rate_limited_keys, all_results]
    """
    if not keys:
        return [], [], {}
    
    logger.info(f"ğŸš€ Starting parallel validation for {len(keys)} keys...")
    start_time = time.time()
    
    # è·å–å¹¶è¡ŒéªŒè¯å™¨å®ä¾‹
    validator = get_parallel_validator(max_workers=10)
    
    # æ‰§è¡Œæ‰¹é‡éªŒè¯
    results = validator.validate_batch(keys)
    
    # åˆ†ç±»ç»“æœ
    valid_keys = []
    rate_limited_keys = []
    
    for key, result in results.items():
        if result.status == "ok":
            valid_keys.append(key)
            logger.info(f"âœ… VALID: {key[:10]}... (response time: {result.response_time:.2f}s)")
        elif result.status == "rate_limited":
            rate_limited_keys.append(key)
            logger.warning(f"âš ï¸ RATE LIMITED: {key[:10]}... (proxy: {result.proxy_used})")
        elif result.status == "invalid":
            logger.info(f"âŒ INVALID: {key[:10]}...")
        else:
            logger.error(f"ğŸ’¥ ERROR: {key[:10]}... - {result.error_message}")
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    elapsed_time = time.time() - start_time
    stats = validator.get_stats()
    
    logger.info(f"ğŸ“Š Parallel validation completed in {elapsed_time:.2f}s")
    logger.info(f"   Total: {len(keys)}, Valid: {len(valid_keys)}, Rate Limited: {len(rate_limited_keys)}")
    logger.info(f"   Average response time: {stats.avg_response_time:.2f}s")
    logger.info(f"   Throughput: {len(keys) / elapsed_time:.2f} keys/second")
    
    # æ˜¾ç¤ºä»£ç†ç»Ÿè®¡
    proxy_stats = validator.get_proxy_stats()
    if proxy_stats:
        logger.info("ğŸŒ Proxy performance:")
        for proxy_url, stats in proxy_stats.items():
            logger.info(f"   {proxy_url}: Success rate {stats['success_rate']:.1%} ({stats['success']}/{stats['total']})")
    
    return valid_keys, rate_limited_keys, results


def process_item_with_parallel_validation(item: Dict[str, Any], content: str) -> Tuple[int, int]:
    """
    ä½¿ç”¨å¹¶è¡ŒéªŒè¯å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆæ›¿ä»£åŸæœ‰çš„ process_item å‡½æ•°ï¼‰
    
    è¿™ä¸ªå‡½æ•°å±•ç¤ºäº†å¦‚ä½•ä¿®æ”¹ç°æœ‰çš„ process_item å‡½æ•°ä»¥ä½¿ç”¨å¹¶è¡ŒéªŒè¯
    """
    import re
    from utils.file_manager import file_manager
    
    # æå–å¯†é’¥
    pattern = r'(AIzaSy[A-Za-z0-9\-_]{33})'
    keys = re.findall(pattern, content)
    
    # è¿‡æ»¤å ä½ç¬¦å¯†é’¥
    filtered_keys = []
    for key in keys:
        context_index = content.find(key)
        if context_index != -1:
            snippet = content[context_index:context_index + 45]
            if "..." in snippet or "YOUR_" in snippet.upper():
                continue
        filtered_keys.append(key)
    
    # å»é‡
    keys = list(set(filtered_keys))
    
    if not keys:
        return 0, 0
    
    logger.info(f"ğŸ”‘ Found {len(keys)} suspected key(s), starting parallel validation...")
    
    # ä½¿ç”¨å¹¶è¡ŒéªŒè¯
    valid_keys, rate_limited_keys, results = integrate_parallel_validation(keys)
    
    # ä¿å­˜ç»“æœ
    repo_name = item["repository"]["full_name"]
    file_path = item["path"]
    file_url = item["html_url"]
    
    if valid_keys:
        file_manager.save_valid_keys(repo_name, file_path, file_url, valid_keys)
        logger.info(f"ğŸ’¾ Saved {len(valid_keys)} valid key(s)")
    
    if rate_limited_keys:
        file_manager.save_rate_limited_keys(repo_name, file_path, file_url, rate_limited_keys)
        logger.info(f"ğŸ’¾ Saved {len(rate_limited_keys)} rate limited key(s)")
    
    return len(valid_keys), len(rate_limited_keys)


# å¼‚æ­¥ç‰ˆæœ¬ç¤ºä¾‹
async def process_items_async(items: List[Dict[str, Any]]) -> Dict[str, List[str]]:
    """
    å¼‚æ­¥å¤„ç†å¤šä¸ªæ–‡ä»¶çš„ç¤ºä¾‹
    """
    import asyncio
    from utils.github_client import GitHubClient
    
    all_keys = []
    item_key_map = {}  # è®°å½•æ¯ä¸ªkeyæ¥è‡ªå“ªä¸ªitem
    
    # æ”¶é›†æ‰€æœ‰å¯†é’¥
    for item in items:
        content = GitHubClient.get_file_content(item)
        if not content:
            continue
        
        # æå–å¯†é’¥
        pattern = r'(AIzaSy[A-Za-z0-9\-_]{33})'
        keys = re.findall(pattern, content)
        
        for key in keys:
            all_keys.append(key)
            if key not in item_key_map:
                item_key_map[key] = []
            item_key_map[key].append(item)
    
    # å»é‡
    unique_keys = list(set(all_keys))
    
    if not unique_keys:
        return {"valid": [], "rate_limited": []}
    
    logger.info(f"ğŸ”‘ Found {len(unique_keys)} unique keys from {len(items)} items")
    
    # åˆ›å»ºéªŒè¯å™¨å¹¶å¼‚æ­¥éªŒè¯
    validator = ParallelKeyValidator(max_workers=20)  # æ›´å¤šå·¥ä½œçº¿ç¨‹
    results = await validator.validate_batch_async(unique_keys)
    
    # åˆ†ç±»ç»“æœ
    valid_keys = []
    rate_limited_keys = []
    
    for key, result in results.items():
        if result.status == "ok":
            valid_keys.append(key)
        elif result.status == "rate_limited":
            rate_limited_keys.append(key)
    
    # å…³é—­éªŒè¯å™¨
    validator.shutdown()
    
    return {
        "valid": valid_keys,
        "rate_limited": rate_limited_keys,
        "results": results,
        "item_map": item_key_map
    }


# æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹
def performance_comparison_demo():
    """
    å±•ç¤ºå¹¶è¡ŒéªŒè¯ä¸ä¸²è¡ŒéªŒè¯çš„æ€§èƒ½å¯¹æ¯”
    """
    import random
    
    # ç”Ÿæˆæµ‹è¯•å¯†é’¥
    test_keys = []
    for i in range(50):
        # æ··åˆæœ‰æ•ˆå’Œæ— æ•ˆçš„å¯†é’¥æ ¼å¼
        if i % 3 == 0:
            key = f"AIzaSy{''.join(random.choices('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_', k=33))}"
        else:
            key = f"AIzaSyINVALID{''.join(random.choices('0123456789', k=27))}"
        test_keys.append(key)
    
    logger.info("=" * 60)
    logger.info("ğŸ Performance Comparison: Serial vs Parallel Validation")
    logger.info("=" * 60)
    
    # ä¸²è¡ŒéªŒè¯ï¼ˆæ¨¡æ‹ŸåŸæœ‰æ–¹å¼ï¼‰
    logger.info("\nğŸ“Š Serial Validation:")
    start_time = time.time()
    serial_results = []
    
    for i, key in enumerate(test_keys):
        # æ¨¡æ‹ŸåŸæœ‰çš„éªŒè¯å»¶è¿Ÿ
        time.sleep(random.uniform(0.5, 1.5))
        serial_results.append("ok" if i % 3 == 0 else "invalid")
        if (i + 1) % 10 == 0:
            logger.info(f"   Progress: {i + 1}/{len(test_keys)}")
    
    serial_time = time.time() - start_time
    logger.info(f"   Total time: {serial_time:.2f}s")
    logger.info(f"   Throughput: {len(test_keys) / serial_time:.2f} keys/second")
    
    # å¹¶è¡ŒéªŒè¯
    logger.info("\nğŸš€ Parallel Validation:")
    validator = ParallelKeyValidator(max_workers=10)
    start_time = time.time()
    
    parallel_results = validator.validate_batch(test_keys)
    
    parallel_time = time.time() - start_time
    stats = validator.get_stats()
    
    logger.info(f"   Total time: {parallel_time:.2f}s")
    logger.info(f"   Throughput: {len(test_keys) / parallel_time:.2f} keys/second")
    logger.info(f"   Average response time: {stats.avg_response_time:.2f}s")
    
    # æ€§èƒ½æå‡
    speedup = serial_time / parallel_time
    logger.info(f"\nğŸ¯ Performance improvement: {speedup:.1f}x faster!")
    logger.info(f"   Time saved: {serial_time - parallel_time:.2f}s")
    
    validator.shutdown()


if __name__ == "__main__":
    # è¿è¡Œæ€§èƒ½å¯¹æ¯”æ¼”ç¤º
    performance_comparison_demo()