"""
å¹¶è¡ŒéªŒè¯ç³»ç»Ÿæ€§èƒ½æµ‹è¯•
å¯¹æ¯”ä¸²è¡ŒéªŒè¯å’Œå¹¶è¡ŒéªŒè¯çš„æ€§èƒ½å·®å¼‚
"""

import sys
import os
import time
import random
import statistics
from datetime import datetime
from typing import List, Dict, Tuple
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from common.Logger import logger
from common.config import Config
from utils.parallel_validator import ParallelKeyValidator, get_parallel_validator

# æ¨¡æ‹ŸåŸæœ‰çš„ä¸²è¡ŒéªŒè¯å‡½æ•°
def validate_gemini_key_serial(api_key: str) -> str:
    """æ¨¡æ‹Ÿä¸²è¡ŒéªŒè¯ï¼ˆåŸæœ‰æ–¹å¼ï¼‰"""
    # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿå’Œå¤„ç†æ—¶é—´
    time.sleep(random.uniform(0.8, 1.2))
    
    # æ¨¡æ‹ŸéªŒè¯ç»“æœï¼ˆ30%æœ‰æ•ˆï¼Œ10%é™æµï¼Œ60%æ— æ•ˆï¼‰
    rand = random.random()
    if rand < 0.3:
        return "ok"
    elif rand < 0.4:
        return "rate_limited"
    else:
        return "invalid"


def generate_test_keys(count: int) -> List[str]:
    """ç”Ÿæˆæµ‹è¯•ç”¨çš„APIå¯†é’¥"""
    keys = []
    for i in range(count):
        # ç”Ÿæˆç¬¦åˆæ ¼å¼çš„æµ‹è¯•å¯†é’¥
        key = f"AIzaSy{''.join(random.choices('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_', k=33))}"
        keys.append(key)
    return keys


def test_serial_validation(keys: List[str]) -> Tuple[Dict[str, int], float]:
    """æµ‹è¯•ä¸²è¡ŒéªŒè¯æ€§èƒ½"""
    logger.info("ğŸ”„ å¼€å§‹ä¸²è¡ŒéªŒè¯æµ‹è¯•...")
    start_time = time.time()
    
    results = {
        "ok": 0,
        "invalid": 0,
        "rate_limited": 0
    }
    
    for i, key in enumerate(keys):
        result = validate_gemini_key_serial(key)
        results[result] = results.get(result, 0) + 1
        
        # æ˜¾ç¤ºè¿›åº¦
        if (i + 1) % 10 == 0:
            elapsed = time.time() - start_time
            rate = (i + 1) / elapsed
            logger.info(f"   è¿›åº¦: {i + 1}/{len(keys)} | é€Ÿç‡: {rate:.2f} keys/s")
    
    total_time = time.time() - start_time
    return results, total_time


def test_parallel_validation(keys: List[str], max_workers: int = 10) -> Tuple[Dict[str, int], float]:
    """æµ‹è¯•å¹¶è¡ŒéªŒè¯æ€§èƒ½"""
    logger.info(f"ğŸš€ å¼€å§‹å¹¶è¡ŒéªŒè¯æµ‹è¯• (å·¥ä½œçº¿ç¨‹: {max_workers})...")
    
    # åˆ›å»ºéªŒè¯å™¨
    validator = ParallelKeyValidator(max_workers=max_workers)
    
    start_time = time.time()
    
    # æ‰§è¡Œæ‰¹é‡éªŒè¯
    validation_results = validator.validate_batch(keys)
    
    # ç»Ÿè®¡ç»“æœ
    results = {
        "ok": 0,
        "invalid": 0,
        "rate_limited": 0,
        "error": 0
    }
    
    for key, result in validation_results.items():
        if result.status == "ok":
            results["ok"] += 1
        elif result.status == "rate_limited":
            results["rate_limited"] += 1
        elif result.status == "invalid":
            results["invalid"] += 1
        else:
            results["error"] += 1
    
    total_time = time.time() - start_time
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = validator.get_stats()
    
    logger.info(f"   å¹³å‡å“åº”æ—¶é—´: {stats.avg_response_time:.2f}s")
    logger.info(f"   æ€»ååé‡: {len(keys) / total_time:.2f} keys/s")
    
    validator.shutdown()
    
    return results, total_time


def run_performance_comparison(test_sizes: List[int] = None):
    """è¿è¡Œå®Œæ•´çš„æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    if test_sizes is None:
        test_sizes = [10, 25, 50, 100]
    
    logger.info("=" * 80)
    logger.info("ğŸ å¹¶è¡ŒéªŒè¯ç³»ç»Ÿæ€§èƒ½æµ‹è¯•")
    logger.info("=" * 80)
    logger.info(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"æµ‹è¯•è§„æ¨¡: {test_sizes}")
    logger.info("")
    
    # å­˜å‚¨æµ‹è¯•ç»“æœ
    test_results = []
    
    for size in test_sizes:
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ“Š æµ‹è¯•è§„æ¨¡: {size} ä¸ªå¯†é’¥")
        logger.info(f"{'='*60}")
        
        # ç”Ÿæˆæµ‹è¯•å¯†é’¥
        test_keys = generate_test_keys(size)
        
        # ä¸²è¡ŒéªŒè¯æµ‹è¯•
        serial_results, serial_time = test_serial_validation(test_keys)
        serial_throughput = size / serial_time
        
        logger.info(f"\nğŸ“ˆ ä¸²è¡ŒéªŒè¯ç»“æœ:")
        logger.info(f"   æ€»è€—æ—¶: {serial_time:.2f}ç§’")
        logger.info(f"   ååé‡: {serial_throughput:.2f} keys/s")
        logger.info(f"   ç»“æœåˆ†å¸ƒ: æœ‰æ•ˆ={serial_results['ok']}, æ— æ•ˆ={serial_results['invalid']}, é™æµ={serial_results['rate_limited']}")
        
        # å¹¶è¡ŒéªŒè¯æµ‹è¯•ï¼ˆä¸åŒå·¥ä½œçº¿ç¨‹æ•°ï¼‰
        parallel_results_list = []
        for workers in [5, 10, 20]:
            if workers > size:  # å·¥ä½œçº¿ç¨‹æ•°ä¸åº”è¶…è¿‡å¯†é’¥æ•°
                continue
                
            logger.info(f"\nğŸš€ å¹¶è¡ŒéªŒè¯ ({workers} å·¥ä½œçº¿ç¨‹):")
            parallel_results, parallel_time = test_parallel_validation(test_keys, max_workers=workers)
            parallel_throughput = size / parallel_time
            
            logger.info(f"   æ€»è€—æ—¶: {parallel_time:.2f}ç§’")
            logger.info(f"   ååé‡: {parallel_throughput:.2f} keys/s")
            logger.info(f"   æ€§èƒ½æå‡: {serial_time / parallel_time:.1f}x")
            logger.info(f"   æ—¶é—´èŠ‚çœ: {serial_time - parallel_time:.2f}ç§’ ({(serial_time - parallel_time) / serial_time * 100:.1f}%)")
            
            parallel_results_list.append({
                "workers": workers,
                "time": parallel_time,
                "throughput": parallel_throughput,
                "speedup": serial_time / parallel_time
            })
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        test_results.append({
            "size": size,
            "serial_time": serial_time,
            "serial_throughput": serial_throughput,
            "parallel_results": parallel_results_list
        })
    
    # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    generate_performance_report(test_results)
    
    return test_results


def generate_performance_report(test_results: List[Dict]):
    """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Šå’Œå›¾è¡¨"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š æ€§èƒ½æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
    logger.info("=" * 80)
    
    # åˆ›å»ºå›¾è¡¨
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('å¹¶è¡ŒéªŒè¯ç³»ç»Ÿæ€§èƒ½æµ‹è¯•æŠ¥å‘Š', fontsize=16, fontweight='bold')
    
    # 1. ååé‡å¯¹æ¯”å›¾
    sizes = [r["size"] for r in test_results]
    serial_throughputs = [r["serial_throughput"] for r in test_results]
    
    ax1.plot(sizes, serial_throughputs, 'r-o', label='ä¸²è¡ŒéªŒè¯', linewidth=2, markersize=8)
    
    # æ·»åŠ ä¸åŒå·¥ä½œçº¿ç¨‹æ•°çš„å¹¶è¡ŒéªŒè¯ç»“æœ
    worker_counts = set()
    for result in test_results:
        for p_result in result["parallel_results"]:
            worker_counts.add(p_result["workers"])
    
    colors = ['g', 'b', 'm', 'c', 'y']
    for i, workers in enumerate(sorted(worker_counts)):
        throughputs = []
        for result in test_results:
            for p_result in result["parallel_results"]:
                if p_result["workers"] == workers:
                    throughputs.append(p_result["throughput"])
                    break
            else:
                throughputs.append(None)
        
        # è¿‡æ»¤æ‰Noneå€¼
        valid_sizes = [s for s, t in zip(sizes, throughputs) if t is not None]
        valid_throughputs = [t for t in throughputs if t is not None]
        
        ax1.plot(valid_sizes, valid_throughputs, f'{colors[i % len(colors)]}-o', 
                label=f'å¹¶è¡Œ ({workers} çº¿ç¨‹)', linewidth=2, markersize=8)
    
    ax1.set_xlabel('å¯†é’¥æ•°é‡', fontsize=12)
    ax1.set_ylabel('ååé‡ (keys/ç§’)', fontsize=12)
    ax1.set_title('ååé‡å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. åŠ é€Ÿæ¯”å›¾
    for result in test_results:
        size = result["size"]
        speedups = [p["speedup"] for p in result["parallel_results"]]
        workers = [p["workers"] for p in result["parallel_results"]]
        
        ax2.plot(workers, speedups, '-o', label=f'{size} keys', linewidth=2, markersize=8)
    
    ax2.set_xlabel('å·¥ä½œçº¿ç¨‹æ•°', fontsize=12)
    ax2.set_ylabel('åŠ é€Ÿæ¯” (å€æ•°)', fontsize=12)
    ax2.set_title('åŠ é€Ÿæ¯” vs å·¥ä½œçº¿ç¨‹æ•°', fontsize=14, fontweight='bold')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.axhline(y=1, color='r', linestyle='--', alpha=0.5)
    
    # 3. æ‰§è¡Œæ—¶é—´å¯¹æ¯”ï¼ˆæŸ±çŠ¶å›¾ï¼‰
    x = range(len(sizes))
    width = 0.2
    
    ax3.bar([i - width*1.5 for i in x], [r["serial_time"] for r in test_results], 
            width, label='ä¸²è¡Œ', color='red', alpha=0.7)
    
    for j, workers in enumerate(sorted(worker_counts)):
        times = []
        for result in test_results:
            for p_result in result["parallel_results"]:
                if p_result["workers"] == workers:
                    times.append(p_result["time"])
                    break
            else:
                times.append(0)
        
        ax3.bar([i - width*0.5 + j*width for i in x], times, 
                width, label=f'å¹¶è¡Œ-{workers}çº¿ç¨‹', alpha=0.7)
    
    ax3.set_xlabel('å¯†é’¥æ•°é‡', fontsize=12)
    ax3.set_ylabel('æ‰§è¡Œæ—¶é—´ (ç§’)', fontsize=12)
    ax3.set_title('æ‰§è¡Œæ—¶é—´å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax3.set_xticks(x)
    ax3.set_xticklabels(sizes)
    ax3.legend()
    ax3.grid(True, axis='y', alpha=0.3)
    
    # 4. æ•ˆç‡æå‡ç™¾åˆ†æ¯”
    improvement_data = []
    labels = []
    
    for result in test_results:
        size = result["size"]
        serial_time = result["serial_time"]
        
        # ä½¿ç”¨10çº¿ç¨‹çš„ç»“æœä½œä¸ºä»£è¡¨
        for p_result in result["parallel_results"]:
            if p_result["workers"] == 10:
                improvement = (serial_time - p_result["time"]) / serial_time * 100
                improvement_data.append(improvement)
                labels.append(f'{size} keys')
                break
    
    bars = ax4.bar(labels, improvement_data, color='green', alpha=0.7)
    ax4.set_ylabel('æ€§èƒ½æå‡ (%)', fontsize=12)
    ax4.set_title('å¹¶è¡ŒéªŒè¯æ€§èƒ½æå‡ç™¾åˆ†æ¯” (10çº¿ç¨‹)', fontsize=14, fontweight='bold')
    ax4.grid(True, axis='y', alpha=0.3)
    
    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
    for bar, value in zip(bars, improvement_data):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height,
                f'{value:.1f}%', ha='center', va='bottom')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    report_path = 'performance_report.png'
    plt.savefig(report_path, dpi=300, bbox_inches='tight')
    logger.info(f"\nğŸ“ˆ æ€§èƒ½æŠ¥å‘Šå›¾è¡¨å·²ä¿å­˜è‡³: {report_path}")
    
    # æ‰“å°æ€»ç»“
    logger.info("\nğŸ¯ å…³é”®å‘ç°:")
    
    # è®¡ç®—å¹³å‡åŠ é€Ÿæ¯”
    all_speedups = []
    for result in test_results:
        for p_result in result["parallel_results"]:
            if p_result["workers"] == 10:  # ä½¿ç”¨10çº¿ç¨‹ä½œä¸ºæ ‡å‡†
                all_speedups.append(p_result["speedup"])
    
    if all_speedups:
        avg_speedup = statistics.mean(all_speedups)
        logger.info(f"   â€¢ å¹³å‡æ€§èƒ½æå‡: {avg_speedup:.1f}x (ä½¿ç”¨10ä¸ªå·¥ä½œçº¿ç¨‹)")
    
    # æ‰¾å‡ºæœ€ä½³é…ç½®
    best_speedup = 0
    best_config = None
    for result in test_results:
        for p_result in result["parallel_results"]:
            if p_result["speedup"] > best_speedup:
                best_speedup = p_result["speedup"]
                best_config = (result["size"], p_result["workers"])
    
    if best_config:
        logger.info(f"   â€¢ æœ€ä½³æ€§èƒ½æå‡: {best_speedup:.1f}x (å¤„ç†{best_config[0]}ä¸ªå¯†é’¥ï¼Œä½¿ç”¨{best_config[1]}ä¸ªå·¥ä½œçº¿ç¨‹)")
    
    # ååé‡æå‡
    max_serial_throughput = max([r["serial_throughput"] for r in test_results])
    max_parallel_throughput = 0
    for result in test_results:
        for p_result in result["parallel_results"]:
            if p_result["throughput"] > max_parallel_throughput:
                max_parallel_throughput = p_result["throughput"]
    
    logger.info(f"   â€¢ æœ€å¤§ååé‡æå‡: ä» {max_serial_throughput:.2f} æå‡åˆ° {max_parallel_throughput:.2f} keys/ç§’")
    
    logger.info("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆï¼")


def run_stress_test(duration_seconds: int = 60):
    """è¿è¡Œå‹åŠ›æµ‹è¯•"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ”¥ å‹åŠ›æµ‹è¯•æ¨¡å¼")
    logger.info("=" * 80)
    logger.info(f"æµ‹è¯•æ—¶é•¿: {duration_seconds}ç§’")
    
    validator = ParallelKeyValidator(max_workers=20)
    
    start_time = time.time()
    total_validated = 0
    batch_times = []
    
    while time.time() - start_time < duration_seconds:
        # ç”Ÿæˆéšæœºæ‰¹æ¬¡å¤§å°çš„å¯†é’¥
        batch_size = random.randint(20, 100)
        keys = generate_test_keys(batch_size)
        
        batch_start = time.time()
        results = validator.validate_batch(keys)
        batch_time = time.time() - batch_start
        
        batch_times.append(batch_time)
        total_validated += len(results)
        
        # æ˜¾ç¤ºè¿›åº¦
        elapsed = time.time() - start_time
        rate = total_validated / elapsed
        logger.info(f"å·²éªŒè¯: {total_validated} | é€Ÿç‡: {rate:.2f} keys/s | æ‰¹æ¬¡æ—¶é—´: {batch_time:.2f}s")
    
    # ç»Ÿè®¡ç»“æœ
    total_time = time.time() - start_time
    avg_batch_time = statistics.mean(batch_times)
    
    logger.info("\nğŸ“Š å‹åŠ›æµ‹è¯•ç»“æœ:")
    logger.info(f"   æ€»éªŒè¯æ•°: {total_validated}")
    logger.info(f"   æ€»æ—¶é•¿: {total_time:.2f}ç§’")
    logger.info(f"   å¹³å‡é€Ÿç‡: {total_validated / total_time:.2f} keys/ç§’")
    logger.info(f"   å¹³å‡æ‰¹æ¬¡æ—¶é—´: {avg_batch_time:.2f}ç§’")
    logger.info(f"   æœ€å¿«æ‰¹æ¬¡: {min(batch_times):.2f}ç§’")
    logger.info(f"   æœ€æ…¢æ‰¹æ¬¡: {max(batch_times):.2f}ç§’")
    
    validator.shutdown()


if __name__ == "__main__":
    # è¿è¡Œæ€§èƒ½å¯¹æ¯”æµ‹è¯•
    logger.info("ğŸš€ å¯åŠ¨å¹¶è¡ŒéªŒè¯ç³»ç»Ÿæ€§èƒ½æµ‹è¯•...")
    
    # åŸºç¡€æ€§èƒ½æµ‹è¯•
    test_results = run_performance_comparison([10, 25, 50, 100, 200])
    
    # å¯é€‰ï¼šè¿è¡Œå‹åŠ›æµ‹è¯•
    # run_stress_test(duration_seconds=30)
    
    logger.info("\nâœ¨ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")